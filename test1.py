# -*- coding: utf-8 -*-import urllib2from bs4 import BeautifulSoupimport xlrdimport xlwtdef download(url):    print 'Downloading:', url    try:        html = urllib2.urlopen(url).read()    except urllib2.URLError as e:        print 'Download error', e.reason        html = None    return html# file inputfile = xlwt.Workbook()table = file.add_sheet('info', cell_overwrite_ok=True)# get informaiton of the housefor page in xrange(1, 10):    url = 'http://bj.lianjia.com/ershoufang/pg%d' % page    # print url    html = download(url)    soup = BeautifulSoup(html, 'html.parser')    # print fixed_html    div = soup.find_all(attrs={'class': 'info clear'}, limit=30)    for detail in div:        row = (div.index(detail)) + (page - 1) * 30        title = detail.find(attrs={'class': 'title'}).text        # print title        table.write(row, 0, title)        houseInfo = detail.find(attrs={'class': 'houseInfo'}).text        # print houseInfo        table.write(row, 1, houseInfo)        positionInfo = detail.find(attrs={'class': 'positionInfo'}).text        # print positionInfo        table.write(row, 2, positionInfo)        if not detail.find(attrs={'class': 'subway'}) is None:            subway = detail.find(attrs={'class': 'subway'}).text            # print subway            table.write(row, 3, subway)        if not detail.find(attrs={'class': 'taxfree'}) is None:            taxfree = detail.find(attrs={'class': 'taxfree'}).text            # print taxfree            table.write(row, 4, taxfree)        totalPrice = detail.find(attrs={'class': 'totalPrice'}).text        # print totalPrice        table.write(row, 5, totalPrice)        UnitPrice = detail.find(attrs={'class': 'unitPrice'}).text        # print UnitPrice        table.write(row, 6, UnitPrice)        # print("----------------------------------------------------------")    print 'No.', page, 'page is got'file.save('lianjiainfo.xls')